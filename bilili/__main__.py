import re
import sys
import argparse
import os
import time

from typing import List
from bilili.utils.base import repair_filename, touch_dir, touch_file, size_format
from bilili.utils.playlist import Dpl, M3u
from bilili.utils.thread import ThreadPool, Flag
from bilili.utils.console import (Console, Font, Line, String, ProgressBar,
                                  LineList, DynamicSymbol, ColorString)
from bilili.utils.subtitle import Subtitle
from bilili.utils.attrdict import AttrDict
from bilili.tools import spider, ass, regex
from bilili.tools import global_status
from bilili.handlers.downloader import RemoteFile
from bilili.handlers.merger import MergingFile
from bilili.video import BililiContainer
from bilili.api.subtitle import get_subtitle
from bilili.api.danmaku import get_danmaku
from bilili.api.exceptions import (ArgumentsError, CannotDownloadError,
                                   UnknownTypeError, UnsupportTypeError, IsPreviewError)


def parse_episodes(episodes_str: str, total: int) -> List[int]:
    """ å°†é€‰é›†å­—ç¬¦ä¸²è½¬ä¸ºåˆ—è¡¨ """

    def reslove_negetive(value):
        return value if value > 0 else value + total + 1

    # è§£æå­—ç¬¦ä¸²ä¸ºåˆ—è¡¨
    print("å…¨ {} è¯".format(total))
    if re.match(r"([\-\d\^\$]+(~[\-\d\^\$]+)?)(,[\-\d\^\$]+(~[\-\d\^\$]+)?)*", episodes_str):
        episodes_str = episodes_str.replace("^", "1")
        episodes_str = episodes_str.replace("$", "-1")
        episode_list = []
        for episode_item in episodes_str.split(","):
            if "~" in episode_item:
                start, end = episode_item.split("~")
                start, end = int(start), int(end)
                start, end = reslove_negetive(start), reslove_negetive(end)
                assert end >= start, "ç»ˆç‚¹å€¼ï¼ˆ{}ï¼‰åº”ä¸å°äºèµ·ç‚¹å€¼ï¼ˆ{}ï¼‰".format(end, start)
                episode_list.extend(list(range(start, end + 1)))
            else:
                episode_item = int(episode_item)
                episode_item = reslove_negetive(episode_item)
                episode_list.append(episode_item)
    else:
        episode_list = []

    episode_list = sorted(list(set(episode_list)))

    # ç­›é€‰æ»¡è¶³æ¡ä»¶çš„å‰§é›†
    out_of_range = []
    episodes = []
    for episode in episode_list:
        if episode in range(1, total + 1):
            if episode not in episodes:
                episodes.append(episode)
        else:
            out_of_range.append(episode)
    if out_of_range:
        print("warn: å‰§é›† {} ä¸å­˜åœ¨".format(",".join(list(map(str, out_of_range)))))

    print("å·²é€‰æ‹©ç¬¬ {} è¯".format(",".join(list(map(str, episodes)))))
    assert episodes, "æ²¡æœ‰é€‰ä¸­ä»»ä½•å‰§é›†"
    return episodes


def main():
    """ è§£æå‘½ä»¤è¡Œå‚æ•°å¹¶è°ƒç”¨ç›¸å…³æ¨¡å—è¿›è¡Œä¸‹è½½ """

    if (sys.version_info.major, sys.version_info.minor) < (3, 8):
        print("è¯·ä½¿ç”¨ Python3.8 åŠä»¥ä¸Šç‰ˆæœ¬å“¦ï½")
        sys.exit(1)

    parser = argparse.ArgumentParser(description="bilili B ç«™è§†é¢‘ã€å¼¹å¹•ä¸‹è½½å™¨")
    parser.add_argument("url", help="è§†é¢‘ä¸»é¡µåœ°å€")
    parser.add_argument(
        "-t", "--type", default="dash", choices=["flv", "dash", "mp4"], help="é€‰æ‹©ä¸‹è½½æºç±»å‹ï¼ˆdash æˆ– flv æˆ– mp4ï¼‰",
    )
    parser.add_argument("-d", "--dir", default=r"", help="ä¸‹è½½ç›®å½•")
    parser.add_argument(
        "-q",
        "--quality",
        default=120,
        choices=[120, 116, 112, 80, 74, 64, 32, 16],
        type=int,
        help="è§†é¢‘æ¸…æ™°åº¦ 120:4K, 116:1080P60, 112:1080P+, 80:1080P, 74:720P60, 64:720P, 32:480P, 16:360P",
    )
    parser.add_argument("-n", "--num-threads", default=16, type=int, help="æœ€å¤§ä¸‹è½½çº¿ç¨‹æ•°")
    parser.add_argument("-p", "--episodes", default="^~$", help="é€‰é›†")
    parser.add_argument("-w", "--overwrite", action="store_true", help="å¼ºåˆ¶è¦†ç›–å·²ä¸‹è½½è§†é¢‘")
    parser.add_argument("-c", "--sess-data", default=None, help="è¾“å…¥ cookies")
    parser.add_argument("-y", "--yes", action="store_true", help="è·³è¿‡ä¸‹è½½è¯¢é—®")
    parser.add_argument(
        "--audio-quality", default=30280,
        choices=[30280, 30232, 30216],
        type=int,
        help="éŸ³é¢‘ç ç‡ç­‰çº§ 30280:320kbps, 30232:128kbps, 30216:64kbps",
    )
    parser.add_argument(
        "--playlist-type", default="dpl", choices=["dpl", "m3u", "no"], help="æ’­æ”¾åˆ—è¡¨ç±»å‹ï¼Œæ”¯æŒ dpl å’Œ m3uï¼Œè¾“å…¥ no ä¸ç”Ÿæˆæ’­æ”¾åˆ—è¡¨",
    )
    parser.add_argument(
        "--danmaku", default="xml", choices=["xml", "ass", "no"], help="å¼¹å¹•ç±»å‹ï¼Œæ”¯æŒ xml å’Œ assï¼Œå¦‚æœè®¾ç½®ä¸º no åˆ™ä¸ä¸‹è½½å¼¹å¹•",
    )
    parser.add_argument(
        "--block-size", default=128, type=int, help="åˆ†å—ä¸‹è½½å™¨çš„å—å¤§å°ï¼Œå•ä½ä¸º MBï¼Œé»˜è®¤ä¸º 128MBï¼Œè®¾ç½®ä¸º 0 æ—¶ç¦ç”¨åˆ†å—ä¸‹è½½",
    )
    parser.add_argument("--abs-path", action="store_true", help="ä¿®æ”¹æ’­æ”¾åˆ—è¡¨è·¯å¾„ç±»å‹ä¸ºç»å¯¹è·¯å¾„")
    parser.add_argument("--use-mirrors", action="store_true", help="å¯ç”¨ä»å¤šä¸ªé•œåƒä¸‹è½½åŠŸèƒ½")
    parser.add_argument("--disable-proxy", action="store_true", help="ç¦ç”¨ç³»ç»Ÿä»£ç†")
    parser.add_argument("--debug", action="store_true", help="debug æ¨¡å¼")

    args = parser.parse_args()
    cookies = {"SESSDATA": args.sess_data}

    config = {
        "url": args.url,
        "dir": args.dir,
        "quality": args.quality,
        "audio_quality": args.audio_quality,
        "episodes": args.episodes,
        "playlist_type": args.playlist_type,
        "playlist_path_type": "AP" if args.abs_path else "RP",
        "overwrite": args.overwrite,
        "cookies": cookies,
        "type": args.type.lower(),
        "block_size": int(args.block_size * 1024 * 1024),
    } >> AttrDict()

    # åŒ¹é…èµ„æºçš„ id ä»¥åŠå…¶å¯¹åº”æ‰€å±ç±»å‹
    # fmt: off
    resource_id = {
        "avid": "",
        "bvid": "",
        "episode_id": "",
        "season_id": "",
    } >> AttrDict()

    # fmt: off
    if (avid_match := regex.acg_video.av.origin.match(args.url)) or \
        (avid_match := regex.acg_video.av.short.match(args.url)):
        from bilili.api.acg_video import get_video_info
        avid = avid_match.group("avid")
        if episode_id := get_video_info(avid=avid)["episode_id"]:
            resource_id.episode_id = episode_id
        else:
            resource_id.avid = avid
    elif (bvid_match := regex.acg_video.bv.origin.match(args.url)) or \
        (bvid_match := regex.acg_video.bv.short.match(args.url)):
        from bilili.api.acg_video import get_video_info
        bvid = bvid_match.group("bvid")
        if episode_id := get_video_info(bvid=bvid)["episode_id"]:
            resource_id.episode_id = episode_id
        else:
            resource_id.bvid = bvid
    elif media_id_match := regex.bangumi.md.origin.match(args.url):
        from bilili.api.bangumi import get_season_id
        media_id = media_id_match.group("media_id")
        resource_id.season_id = get_season_id(media_id=media_id)
    elif (episode_id_match := regex.bangumi.ep.origin.match(args.url)) or \
        (episode_id_match := regex.bangumi.ep.short.match(args.url)):
        episode_id = episode_id_match.group("episode_id")
        resource_id.episode_id = episode_id
    elif (season_id_match := regex.bangumi.ss.origin.match(args.url)) or \
        (season_id_match := regex.bangumi.ss.short.match(args.url)):
        season_id = season_id_match.group("season_id")
        resource_id.season_id = season_id
    else:
        print("è§†é¢‘åœ°å€æœ‰è¯¯ï¼")
        sys.exit(1)

    if resource_id.avid or resource_id.bvid:
        from bilili.parser.acg_video import get_title, get_list, get_playurl
        bili_type = "acg_video"
    elif resource_id.season_id or resource_id.episode_id:
        from bilili.parser.bangumi import get_title, get_list, get_playurl
        bili_type = "bangumi"

    # è·å–æ ‡é¢˜
    spider.set_cookies(config["cookies"])
    if args.disable_proxy:
        spider.trust_env = False
    title = get_title(resource_id)
    print(title)

    # åˆ›å»ºæ‰€éœ€ç›®å½•ç»“æ„
    base_dir = touch_dir(os.path.join(config["dir"], repair_filename(title + " - bilibili")))
    video_dir = touch_dir(os.path.join(base_dir, "Videos"))

    # è·å–éœ€è¦çš„ä¿¡æ¯
    containers = [BililiContainer(video_dir=video_dir, type=args.type, **video) for video in get_list(resource_id)]

    # è§£æå¹¶è¿‡æ»¤ä¸éœ€è¦çš„é€‰é›†
    episodes = parse_episodes(config["episodes"], len(containers))
    containers, containers_need_filter = [], containers
    for container in containers_need_filter:
        if container.id not in episodes:
            container._.downloaded = True
            container._.merged = True
        else:
            containers.append(container)

    # åˆå§‹åŒ–æ’­æ”¾åˆ—è¡¨
    if config["playlist_type"] == "dpl":
        playlist = Dpl(os.path.join(base_dir, "Playlist.dpl"), path_type=config["playlist_path_type"])
    elif config["playlist_type"] == "m3u":
        playlist = M3u(os.path.join(base_dir, "Playlist.m3u"), path_type=config["playlist_path_type"])
    else:
        playlist = None

    # è§£æç‰‡æ®µä¿¡æ¯åŠè§†é¢‘ url
    for i, container in enumerate(containers):
        print(
            "{:02}/{:02} parsing segments info...".format(i + 1, len(containers)), end="\r",
        )

        # è§£æè§†é¢‘ url
        try:
            for playinfo in get_playurl(container, config["quality"], config["audio_quality"]):
                container.append_media(
                    block_size=config["block_size"],
                    **playinfo
                )
        except CannotDownloadError as e:
            print('[warn] {} æ— æ³•ä¸‹è½½ï¼ŒåŸå› ï¼š{}'.format(container.name, e.message))
        except IsPreviewError:
            print('[warn] {} æ˜¯é¢„è§ˆè§†é¢‘'.format(container.name))

        # å†™å…¥æ’­æ”¾åˆ—è¡¨
        if playlist is not None:
            playlist.write_path(container.path)

        # ä¸‹è½½å¼¹å¹•
        if bili_type == "acg_video":
            for sub_info in get_subtitle(avid=resource_id.avid, bvid=resource_id.bvid, cid=container.meta['cid']):
                sub_path = '{}_{}.srt'.format(os.path.splitext(container.path)[0], sub_info['lang'])
                subtitle = Subtitle(sub_path)
                for sub_line in sub_info['lines']:
                    subtitle.write_line(sub_line["content"], sub_line["from"], sub_line["to"])

        # ç”Ÿæˆå¼¹å¹•
        if args.danmaku != "no":
            with open(os.path.splitext(container.path)[0] + ".xml", 'w', encoding='utf-8') as f:
                f.write(get_danmaku(container.meta['cid']))

        # è½¬æ¢å¼¹å¹•ä¸º ASS
        if args.danmaku == "ass":
            ass.convert_danmaku_from_xml(
                os.path.splitext(container.path)[0] + ".xml", container.height, container.width,
            )
    if playlist is not None:
        playlist.flush()

    # å‡†å¤‡ä¸‹è½½
    if containers:
        # çŠ¶æ€æ£€æŸ¥ä¸æ ¡æ­£
        for i, container in enumerate(containers):
            container_downloaded = not container.check_needs_download(args.overwrite)
            symbol = "âœ“" if container_downloaded else "âœ–"
            if container_downloaded:
                container._.merged = True
            print("{} {}".format(symbol, str(container)))
            for media in container.medias:
                media_downloaded = not media.check_needs_download(args.overwrite) or container_downloaded
                symbol = "âœ“" if media_downloaded else "âœ–"
                if not container_downloaded:
                    print("    {} {}".format(symbol, media.name))
                for block in media.blocks:
                    block_downloaded = not block.check_needs_download(args.overwrite) or media_downloaded
                    symbol = "âœ“" if block_downloaded else "âœ–"
                    block._.downloaded = block_downloaded
                    if not media_downloaded and args.debug:
                        print("        {} {}".format(symbol, block.name))

        # è¯¢é—®æ˜¯å¦ä¸‹è½½ï¼Œé€šè¿‡å‚æ•° -y å¯ä»¥è·³è¿‡
        if not args.yes:
            answer = None
            while answer is None:
                result = input("ä»¥ä¸Šæ ‡ âœ– ä¸ºéœ€è¦è¿›è¡Œä¸‹è½½çš„è§†é¢‘ï¼Œæ˜¯å¦ç«‹åˆ»è¿›è¡Œä¸‹è½½ï¼Ÿ[Y/n]")
                if result == "" or result[0].lower() == "y":
                    answer = True
                elif result[0].lower() == "n":
                    answer = False
                else:
                    answer = None
            if not answer:
                sys.exit(0)

        # éƒ¨ç½²ä¸‹è½½ä¸åˆå¹¶ä»»åŠ¡
        merge_wait_flag = Flag(False)  # åˆå¹¶çº¿ç¨‹æ± ä¸èƒ½å› ä¸ºæ²¡æœ‰ä»»åŠ¡å°±ç»“æŸ
        # å› æ­¤è¦è®¾å®šä¸€ä¸ª flagï¼Œå¾…æœ€ååˆå¹¶ç»“æŸåæ”¹å˜å…¶å€¼
        merge_pool = ThreadPool(3, wait=merge_wait_flag, daemon=True)
        download_pool = ThreadPool(args.num_threads, daemon=True, thread_globals_creator={
            "thread_spider":spider.clone            # ä¸ºæ¯ä¸ªçº¿ç¨‹åˆ›å»ºä¸€ä¸ªå…¨æ–°çš„ Sessionï¼Œå› ä¸º requests.Session ä¸æ˜¯çº¿ç¨‹å®‰å…¨çš„
                                                    # https://github.com/psf/requests/issues/1871
        })
        for container in containers:
            merging_file = MergingFile(container.type, [media.path for media in container.medias], container.path,)
            for media in container.medias:

                block_merging_file = MergingFile(None, [block.path for block in media.blocks], media.path)
                for block in media.blocks:

                    mirrors = block.mirrors if args.use_mirrors else []
                    remote_file = RemoteFile(block.url, block.path, mirrors=mirrors, range=block.range)

                    # ä¸ºä¸‹è½½æŒ‚è½½å„ç§é’©å­ï¼Œä»¥ä¿®æ”¹çŠ¶æ€ï¼Œæ³¨æ„å¤–éƒ¨å˜é‡åº”å½“ä½œä¸ºé»˜è®¤å‚æ•°ä¼ å…¥
                    @remote_file.on("before_download")
                    def before_download(file, status=block._):
                        status.downloading = True

                    @remote_file.on("updated")
                    def updated(file, status=block._):
                        status.size = file.size

                    @remote_file.on("downloaded")
                    def downloaded(file, status=block._, merging_file=merging_file, block_merging_file=block_merging_file):
                        status.downloaded = True

                        if status.parent.downloaded:
                            # å½“å‰ media çš„æœ€åä¸€ä¸ª block æ‰€åœ¨çº¿ç¨‹è¿›è¡Œåˆå¹¶ï¼ˆç›´æ¥æ‰§è¡Œï¼Œä¸æ”¾çº¿ç¨‹æ± ï¼‰
                            status.downloaded = False
                            block_merging_file.merge()
                            status.downloaded = True

                            # å¦‚æœè¯¥çº¿ç¨‹åŒæ—¶ä¹Ÿæ˜¯å½“å‰ container çš„æœ€åä¸€ä¸ª blockï¼Œå°±éƒ¨ç½²åˆå¹¶ä»»åŠ¡ï¼ˆæ”¾åˆ°çº¿ç¨‹æ± ï¼‰
                            if status.parent.parent.downloaded and not status.parent.parent.merged:
                                # ä¸ºåˆå¹¶æŒ‚è½½å„ç§é’©å­
                                @merging_file.on("before_merge")
                                def before_merge(file, status=status.parent.parent):
                                    status.merging = True

                                @merging_file.on("merged")
                                def merged(file, status=status.parent.parent):
                                    status.merging = False
                                    status.merged = True

                                merge_pool.add_task(merging_file.merge, args=())

                        status.downloading = False

                    # ä¸‹è½½è¿‡çš„ä¸åº”ç»§ç»­éƒ¨ç½²ä»»åŠ¡
                    if block._.downloaded:
                        continue
                    download_pool.add_task(remote_file.download, args=())

        # å¯åŠ¨çº¿ç¨‹æ± 
        merge_pool.run()
        download_pool.run()

        # åˆå§‹åŒ–ç•Œé¢
        console = Console(debug=args.debug)
        console.add_component(Line(center=Font(char_a="ğ“ª", char_A="ğ“"), fillchar=" "))
        console.add_component(Line(left=ColorString(fore="cyan"), fillchar=" "))
        console.add_component(LineList(Line(left=String(), right=String(), fillchar="-")))
        console.add_component(
            Line(
                left=ColorString(fore="green", back="white", subcomponent=ProgressBar(symbols=" â–â–â–â–Œâ–‹â–Šâ–‰â–ˆ", width=65),),
                right=String(),
                fillchar=" ",
            )
        )
        console.add_component(Line(left=ColorString(fore="blue"), fillchar=" "))
        console.add_component(LineList(Line(left=String(), right=DynamicSymbol(symbols="ğŸŒ‘ğŸŒ’ğŸŒ“ğŸŒ”ğŸŒ•ğŸŒ–ğŸŒ—ğŸŒ˜"), fillchar=" ")))
        console.add_component(
            Line(
                left=ColorString(fore="yellow", back="white", subcomponent=ProgressBar(symbols=" â–â–â–â–Œâ–‹â–Šâ–‰â–ˆ", width=65),),
                right=String(),
                fillchar=" ",
            )
        )

        # å‡†å¤‡ç›‘æ§
        size, t = global_status.size, time.time()
        while True:
            now_size, now_t = global_status.size, time.time()
            delta_size, delta_t = (
                max(now_size - size, 0),
                (now_t - t) if now_t - t > 1e-6 else 1e-6,
            )
            speed = delta_size / delta_t
            size, t = now_size, now_t

            # æ•°æ®ä¼ å…¥ï¼Œç•Œé¢æ¸²æŸ“
            console.refresh(
                # fmt: off
                [
                    {
                        "center": " ğŸ» bilili ",
                    },
                    {
                        "left": "ğŸŒ  Downloading videos: "
                    } if global_status.downloading else None,
                    [
                        {
                            "left": "{} ".format(str(container)),
                            "right": " {}/{}".format(
                                size_format(container._.size), size_format(container._.total_size),
                            ),
                        } if container._.downloading else None
                        for container in containers
                    ] if global_status.downloading else None,
                    {
                        "left": global_status.size / global_status.total_size,
                        "right": " {}/{} {}/s âš¡".format(
                            size_format(global_status.size),
                            size_format(global_status.total_size),
                            size_format(speed),
                        ),
                    } if global_status.downloading else None,
                    {
                        "left": "ğŸ° Merging videos: "
                    } if global_status.merging else None,
                    [
                        {
                            "left": "{} ".format(str(container)),
                            "right": True
                        } if container._.merging else None
                        for container in containers
                    ] if global_status.merging else None,
                    {
                        "left": sum([container._.merged for container in containers]) / len(containers),
                        "right": " {}/{} ğŸš€".format(
                            sum([container._.merged for container in containers]), len(containers),
                        ),
                    } if global_status.merging else None,
                ]
            )

            # æ£€æŸ¥æ˜¯å¦å·²ç»å…¨éƒ¨å®Œæˆ
            if global_status.downloaded and global_status.merged:
                merge_wait_flag.value = True
                download_pool.join()
                merge_pool.join()
                break
            try:
                # å°†åˆ·æ–°ç‡ç¨³å®šåœ¨ 2fps
                refresh_rate = 2
                time.sleep(max(1 / refresh_rate - (time.time() - now_t), 0.01))
            except (SystemExit, KeyboardInterrupt):
                raise
        print("å·²å…¨éƒ¨ä¸‹è½½å®Œæˆï¼")
    else:
        print("æ²¡æœ‰éœ€è¦ä¸‹è½½çš„è§†é¢‘ï¼")


if __name__ == "__main__":
    main()
